name: Get WandB Run Artifacts
on:
  issue_comment:
    types: [created]

jobs:
  get-run-artifacts:
    # Condition to run only on PR comments with the specific trigger phrase
    if: github.event.issue.pull_request != null && startsWith(github.event.comment.body, '/wandb_get_artifact')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Extract Run ID from comment
        id: extract_run_id
        run: |
          # Extracts the part after '/wandb_get_artifact '
          # Example: /wandb_get_artifact 123xyz -> 123xyz
          COMMENT_BODY="${{ github.event.comment.body }}"
          TRIGGER_PHRASE="/wandb_get_artifact "
          RUN_ID=$(echo "$COMMENT_BODY" | sed "s|^$TRIGGER_PHRASE||")
          
          # Basic validation: check if RUN_ID is not empty and doesn't contain spaces
          if [ -z "$RUN_ID" ] || [[ "$RUN_ID" == *' '* ]]; then
            echo "Error: Run ID not provided or invalid format after trigger phrase."
            echo "Usage: /wandb_get_artifact <run_id>"
            # Create a simple error markdown to be posted
            echo "### âš ï¸ Invalid Command" > artifact_summary.md
            echo "Run ID not provided or invalid after trigger phrase." >> artifact_summary.md
            echo "Please use the format: \`/wandb_get_artifact <run_id>\`" >> artifact_summary.md
            echo "::set-output name=parse_error::true"
          else
            echo "Extracted Run ID: $RUN_ID"
            echo "::set-output name=run_id::$RUN_ID"
            echo "::set-output name=parse_error::false"
          fi
        shell: bash

      - name: Setup Python
        if: steps.extract_run_id.outputs.parse_error == 'false'
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          
      - name: Install wandb library
        if: steps.extract_run_id.outputs.parse_error == 'false'
        run: pip install wandb pandas # pandas for potentially displaying tables

      - name: Create Python script for fetching artifacts
        if: steps.extract_run_id.outputs.parse_error == 'false'
        run: |
          cat > wandb_artifact_script.py << 'SCRIPT_EOF'
          import os
          import wandb
          import pandas as pd # For table display
          from datetime import datetime

          # Get environment variables
          # WANDB_RUN_ID is passed from the previous step's output
          run_id = os.environ.get("WANDB_RUN_ID") 
          entity = os.environ.get("WANDB_ENTITY")
          project = os.environ.get("WANDB_PROJECT")

          output_file = "artifact_summary.md"

          def format_size(size_bytes):
              if size_bytes is None: return "N/A"
              if size_bytes == 0: return "0B"
              size_name = ("B", "KB", "MB", "GB", "TB")
              import math
              i = int(math.floor(math.log(size_bytes, 1024)))
              p = math.pow(1024, i)
              s = round(size_bytes / p, 2)
              return f"{s} {size_name[i]}"

          def generate_artifact_report():
              if not all([run_id, entity, project]):
                  with open(output_file, "w") as f:
                      f.write("### âš ï¸ Configuration Error\n\n")
                      f.write("Missing one or more required environment variables: `WANDB_RUN_ID`, `WANDB_ENTITY`, `WANDB_PROJECT`.\n")
                      f.write("Ensure `WANDB_ENTITY` and `WANDB_PROJECT` are set as GitHub secrets.\n")
                  print("Error: Missing environment variables.")
                  return

              print(f"Fetching artifacts for Run ID: {run_id} in project {entity}/{project}")
              
              api = wandb.Api(timeout=60)
              
              try:
                  run = api.run(f"{entity}/{project}/{run_id}")
                  print(f"Successfully fetched run: {run.name} (ID: {run.id})")
              except Exception as e:
                  print(f"Error fetching run '{run_id}': {e}")
                  with open(output_file, "w") as f:
                      f.write(f"### âŒ Error Fetching Run\n\n")
                      f.write(f"Could not fetch W&B Run with ID: `{run_id}` for project `{entity}/{project}`.\n")
                      f.write(f"**Details:** {str(e)}\n\n")
                      f.write("Please ensure the Run ID is correct and the necessary permissions are available.")
                  return

              # Fetch logged artifacts. run.artifacts could also be used.
              # run.logged_artifacts() usually returns artifacts explicitly logged via `run.log_artifact()`
              artifacts = run.logged_artifacts()
              
              with open(output_file, "w") as f:
                  f.write(f"# ðŸº Artifact Report for W&B Run: `{run.name}`\n")
                  f.write(f"**Run ID:** `{run.id}` | **Project:** `{entity}/{project}`\n")
                  f.write(f"**Created At:** {run.created_at} | **State:** {run.state}\n\n")
                  
                  if not artifacts:
                      f.write("## â„¹ï¸ No Artifacts Found\n\n")
                      f.write("This run does not have any logged artifacts.\n")
                  else:
                      f.write(f"## ðŸ“œ Artifacts Summary ({len(artifacts)})\n\n")
                      for idx, artifact in enumerate(artifacts):
                          f.write(f"### {idx+1}. {artifact.name} (Type: `{artifact.type}`)\n")
                          f.write(f"- **Version:** `{artifact.version}` (ID: `{artifact.id}`)\n")
                          f.write(f"- **Digest:** `{artifact.digest}`\n")
                          f.write(f"- **Size:** {format_size(artifact.size)}\n")
                          f.write(f"- **Created At:** {artifact.created_at}\n")
                          
                          if artifact.description:
                              f.write(f"- **Description:** {artifact.description}\n")
                          
                          if artifact.metadata:
                              f.write("- **Metadata:**\n")
                              for k, v in artifact.metadata.items():
                                  f.write(f"  - `{k}`: `{v}`\n")
                          
                          # Attempt to preview content for specific types
                          try:
                              if artifact.type == 'dataset' or artifact.type == 'table' or 'table' in artifact.name.lower():
                                  # Check for manifest entries, especially tables
                                  manifest_entries = list(artifact.manifest.entries.keys())
                                  table_files = [entry for entry in manifest_entries if entry.endswith('.table.json')]
                                  if table_files:
                                      f.write("- **Preview (Table):**\n")
                                      # For simplicity, we'll just indicate a table is present.
                                      # Downloading and parsing tables can be complex here.
                                      # A more advanced version might download and show a few rows.
                                      f.write(f"  - Contains table data (e.g., `{table_files[0]}`). View on W&B for details.\n")
                                  else:
                                      f.write(f"  - Dataset artifact. Contains {len(manifest_entries)} files/references.\n")

                              elif artifact.type == 'model':
                                  f.write("- **Preview (Model):**\n")
                                  f.write(f"  - Model artifact. Contains files related to a trained model.\n")
                                  # List some files if available in manifest
                                  if artifact.manifest:
                                      model_files = list(artifact.manifest.entries.keys())[:3] # Show first 3 files
                                      if model_files:
                                          f.write(f"  - Example files: `{', '.join(model_files)}`\n")
                              
                              # Simple text file preview (if a single small text file)
                              elif len(artifact.manifest.entries) == 1:
                                  entry_name = list(artifact.manifest.entries.keys())[0]
                                  if entry_name.endswith(('.txt', '.json', '.yaml', '.yml', '.md', '.csv', '.log')):
                                      # Downloading artifact content in action can be slow/complex for large files
                                      # For now, just indicate the file type.
                                      # A more robust solution would download and show a snippet if size is small.
                                      f.write(f"- **Content Hint:** Contains a `{entry_name.split('.')[-1]}` file: `{entry_name}`.\n")

                          except Exception as preview_e:
                              print(f"Could not generate preview for {artifact.name}: {preview_e}")
                              f.write("- *Preview generation encountered an issue.*\n")

                          f.write(f"- **[âž¡ï¸ View Artifact on W&B](https{':'.join(str(run.url).split(':')[1:])}/artifacts/{artifact.type}/{artifact.name.replace(':', '%3A')}/{artifact.version})**\n") # Construct artifact URL
                          f.write("\n---\n\n")
                  
                  f.write(f"\n*Report generated by WandB GitHub Action at {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S %Z')} UTC* ðŸ¤–\n")
                  f.write(f"*View full run details: [W&B Run Page]({run.url})*")

              print(f"Artifact report generated: {output_file}")

          if __name__ == "__main__":
              generate_artifact_report()
          SCRIPT_EOF

      - name: Execute Python script to fetch artifacts
        if: steps.extract_run_id.outputs.parse_error == 'false'
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          WANDB_ENTITY: ${{ secrets.WANDB_ENTITY }}    # Your W&B username or team name
          WANDB_PROJECT: ${{ secrets.WANDB_PROJECT }}  # Your W&B project name
          WANDB_RUN_ID: ${{ steps.extract_run_id.outputs.run_id }} # Pass the extracted run_id
        run: python wandb_artifact_script.py
        
      - name: Debug - Display generated markdown content
        if: always() # Run this step even if previous steps fail, for debugging
        run: |
          echo "--- Generated Markdown Content (artifact_summary.md) ---"
          if [ -f artifact_summary.md ]; then
            cat artifact_summary.md
          else
            echo "artifact_summary.md not found."
          fi
          echo "--- End of Markdown Content ---"
          
      - name: Install GitHub CLI
        run: |
          # Ensure apt sources are updated before trying to install
          sudo apt-get update -y
          sudo apt-get install -y gh
          
      - name: Comment to PR with Artifact Summary
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.issue.number }}
        run: |
          echo "Attempting to comment on PR #$PR_NUMBER with artifact_summary.md"
          if [ -f artifact_summary.md ]; then
            gh pr comment $PR_NUMBER --body-file artifact_summary.md
            echo "Successfully commented on PR #$PR_NUMBER."
          else
            echo "Error: artifact_summary.md not found. Cannot comment."
            # Optionally, post a generic error comment if the file is missing
            # gh pr comment $PR_NUMBER --body "Error: Could not generate W&B artifact report."
            exit 1 # Indicate failure
          fi
